"""
æ‰¹é‡ç”Ÿæˆ Plan A/B/C çš„å¯¹æ¯”å›¾
- é¢„æµ‹ç²¾åº¦åˆ†æï¼ˆå¾®è§‚è§†å›¾ + ç›¸å…³æ€§ï¼‰
- GOEè°±åˆ†æï¼ˆèƒ½çº§é—´è·ç»Ÿè®¡ï¼‰
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from sympy import primerange
import os
from pathlib import Path

# ==================== é…ç½®åŒº ====================
WEIGHT_DIR = r"D:\pythonstudy\python_task\æƒé‡åˆ†æ"
OUTPUT_DIR = r"D:\pythonstudy\python_task\æƒé‡åˆ†æ\è®ºæ–‡å›¾ç‰‡"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# å®éªŒé…ç½®
EXPERIMENTS = {
    "Plan_A": {
        "weight_file": "Plan A.pt",
        "learnable_embedding": True,
        "label": "Plan A (Learnable + Large Batch)",
        "color": "#E74C3C"  # çº¢è‰²
    },
    "Plan_B": {
        "weight_file": "Plan B.pt",
        "learnable_embedding": True,
        "label": "Plan B (Learnable + Small Batch)",
        "color": "#3498DB"  # è“è‰²
    },
    "Plan_C": {
        "weight_file": "Plan C.pt",
        "learnable_embedding": False,  # æ­£å¼¦æ³¢ç¼–ç 
        "label": "Plan C (Sinusoidal + Large Batch)",
        "color": "#2ECC71"  # ç»¿è‰²
    }
}

# æ¨¡å‹å‚æ•°
D_MODEL = 256
N_LAYERS = 6
N_HEADS = 8
DROPOUT = 0.1
NUM_PRIMES = 1000000

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}\n")

# ==================== æ¨¡å‹å®šä¹‰ ====================
class RiemannEmbedding(nn.Module):
    def __init__(self, d_model, max_len=1000000, learnable=True):
        super().__init__()
        self.learnable = learnable
        if learnable:
            self.embedding = nn.Embedding(max_len, d_model)
        else:
            # æ­£å¼¦æ³¢ç¼–ç 
            pe = torch.zeros(max_len, d_model)
            position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
            div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))
            pe[:, 0::2] = torch.sin(position * div_term)
            pe[:, 1::2] = torch.cos(position * div_term)
            self.register_buffer('pe', pe)

    def forward(self, x):
        if self.learnable:
            return self.embedding(x)
        else:
            return self.pe[x]

class PrimeGapPredictor(nn.Module):
    def __init__(self, learnable_embedding=True):
        super().__init__()
        self.riemann_embedding = RiemannEmbedding(D_MODEL, NUM_PRIMES, learnable=learnable_embedding)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=D_MODEL,
            nhead=N_HEADS,
            dim_feedforward=D_MODEL*4,
            dropout=DROPOUT,
            batch_first=True,
            norm_first=True,
            activation='gelu'
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=N_LAYERS)
        self.output = nn.Sequential(
            nn.Linear(D_MODEL, D_MODEL // 2),
            nn.GELU(),
            nn.Dropout(DROPOUT),
            nn.Linear(D_MODEL // 2, D_MODEL // 4),
            nn.GELU(),
            nn.Dropout(DROPOUT),
            nn.Linear(D_MODEL // 4, 1)
        )
    
    def forward(self, x):
        embedded = self.riemann_embedding(x).unsqueeze(1)
        transformed = self.transformer(embedded)
        return self.output(transformed.squeeze(1))

# ==================== åˆ†æå‡½æ•° ====================

def load_model(weight_path, learnable_embedding):
    """åŠ è½½æ¨¡å‹"""
    model = PrimeGapPredictor(learnable_embedding=learnable_embedding).to(device)
    checkpoint = torch.load(weight_path, map_location=device, weights_only=False)
    state = checkpoint['model_state_dict'] if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint else checkpoint
    model.load_state_dict(state)
    model.eval()
    return model

def analyze_prediction_accuracy(model, plan_name, color):
    """é¢„æµ‹ç²¾åº¦åˆ†æï¼ˆå®Œå…¨ç…§æŠ„æºä»£ç ï¼‰"""
    print(f"  ğŸ” åˆ†æé¢„æµ‹ç²¾åº¦...")
    
    # ç”Ÿæˆå…¨éƒ¨ç´ æ•°å¹¶è®¡ç®—å…¨å±€ç»Ÿè®¡é‡
    all_primes = list(primerange(1, 18500000))[:NUM_PRIMES]
    all_gaps = np.diff(all_primes)
    
    global_mean = np.mean(all_gaps)
    global_std = np.std(all_gaps)
    
    # å–æœ€å1000ä¸ªgap
    total_gaps = len(all_gaps)
    target_len = 1000
    start_idx = total_gaps - target_len
    end_idx = total_gaps
    target_gaps = all_gaps[start_idx:end_idx]
    
    # é¢„æµ‹
    indices = torch.arange(start_idx, end_idx, device=device)
    with torch.no_grad():
        preds_norm = model(indices).squeeze().cpu().numpy()
    
    # è¿˜åŸå½’ä¸€åŒ–
    preds_real = (preds_norm * global_std) + global_mean
    
    # è®¡ç®—è¯¯å·®
    mae = np.mean(np.abs(preds_real - target_gaps))
    
    # ç»˜å›¾ï¼ˆå®Œå…¨ç…§æŠ„æºä»£ç ï¼‰
    plt.figure(figsize=(18, 6))
    
    # å·¦å›¾ï¼šå¾®è§‚è§†å›¾ (å‰200ä¸ª)
    plt.subplot(1, 2, 1)
    plt.plot(target_gaps[:200], color='black', alpha=0.6, label='Real Truth', linewidth=2)
    plt.plot(preds_real[:200], color='red', alpha=0.8, linestyle='--', label='AI Prediction', linewidth=1.5)
    plt.title(f'Micro View: First 200 of Last 1000 Gaps')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # å³å›¾ï¼šæ•´ä½“ç›¸å…³æ€§
    plt.subplot(1, 2, 2)
    plt.scatter(target_gaps, preds_real, alpha=0.5, s=10, c='blue')
    min_v = min(target_gaps.min(), preds_real.min())
    max_v = max(target_gaps.max(), preds_real.max())
    plt.plot([min_v, max_v], [min_v, max_v], 'r--', label='Perfect Fit')
    plt.title(f'Correlation (MAE={mae:.4f})')
    plt.xlabel('Real Gap')
    plt.ylabel('Predicted Gap')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    save_path = os.path.join(OUTPUT_DIR, f'{plan_name}_prediction.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"    âœ… MAE = {mae:.4f}, å›¾ç‰‡å·²ä¿å­˜")
    return mae

def analyze_goe_spectrum(model, plan_name, color):
    """GOEè°±åˆ†æ"""
    print(f"  ğŸ”¬ åˆ†æGOEè°±...")
    
    # æå–æƒé‡
    weights = []
    for name, param in model.named_parameters():
        if 'in_proj_weight' in name:
            weights.append(param.detach().cpu().numpy())
    
    if not weights:
        for name, param in model.named_parameters():
            if len(param.shape)==2 and param.shape[0]==param.shape[1]:
                weights.append(param.detach().cpu().numpy())
    
    if not weights:
        print("    âš ï¸ æœªæ‰¾åˆ°å¯ç”¨æƒé‡çŸ©é˜µ")
        return None
    
    # æ‹¼æ¥å¹¶æˆªå–
    W_huge = np.concatenate(weights, axis=0)
    n = min(2048, W_huge.shape[0], W_huge.shape[1])
    W = W_huge[:n, :n]
    
    # å„ç±³åŒ–
    H = (W + W.T) / 2
    eigvals = np.linalg.eigvalsh(H)
    
    # è®¡ç®—èƒ½çº§é—´è·
    eigvals = np.sort(eigvals)
    limit_low = int(n * 0.15)
    limit_high = int(n * 0.85)
    eigvals = eigvals[limit_low : limit_high]
    spacings = np.diff(eigvals)
    s = spacings / np.mean(spacings)
    
    # ç»˜å›¾
    fig, ax = plt.subplots(figsize=(10, 6))
    
    ax.hist(s, bins=70, density=True, alpha=0.65, color=color, edgecolor='black', label=f'AI Weights ({plan_name})')
    
    x = np.linspace(0, 4, 300)
    
    # GOEæ›²çº¿ï¼ˆå®å¯¹ç§°çŸ©é˜µçš„ç†è®ºåˆ†å¸ƒï¼‰
    p_goe = (np.pi / 2) * x * np.exp(-np.pi * x**2 / 4)
    ax.plot(x, p_goe, 'r-', linewidth=3, label='GOE (Time-Reversal Symmetric Chaos)')
    
    # Poissonæ›²çº¿
    p_poisson = np.exp(-x)
    ax.plot(x, p_poisson, 'g--', linewidth=3, label='Poisson (Random)')
    
    ax.set_title(f'{plan_name}: Level Spacing Statistics', fontsize=14, fontweight='bold')
    ax.set_xlabel('Normalized Spacing (s)', fontsize=12)
    ax.set_ylabel('Probability Density P(s)', fontsize=12)
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3)
    ax.set_xlim(0, 3.5)
    
    plt.tight_layout()
    save_path = os.path.join(OUTPUT_DIR, f'{plan_name}_goe_spectrum.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    # è®¡ç®—è·ç¦»
    def calc_distance(data, func):
        y_hist, bins = np.histogram(data, bins=100, density=True, range=(0, 3))
        centers = (bins[:-1] + bins[1:]) / 2
        return np.mean(np.abs(y_hist - func(centers)))
    
    d_goe = calc_distance(s, lambda x: (np.pi / 2) * x * np.exp(-np.pi * x**2 / 4))
    d_poisson = calc_distance(s, lambda x: np.exp(-x))
    verdict = "GOE" if d_goe < d_poisson else "Poisson"
    
    print(f"    âœ… {verdict} (d_GOE={d_goe:.4f}, d_Poisson={d_poisson:.4f})")
    return {"verdict": verdict, "d_goe": d_goe, "d_poisson": d_poisson}

# ==================== ä¸»æµç¨‹ ====================

def main():
    print("="*60)
    print("ğŸš€ æ‰¹é‡ç”Ÿæˆ Plan A/B/C å¯¹æ¯”å›¾")
    print("="*60)
    
    results = {}
    
    for plan_name, config in EXPERIMENTS.items():
        print(f"\nğŸ“¦ å¤„ç† {plan_name}...")
        
        # æ„å»ºæƒé‡è·¯å¾„
        weight_path = os.path.join(WEIGHT_DIR, config["weight_file"])
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(weight_path):
            print(f"  âš ï¸ æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {weight_path}")
            print(f"  ğŸ’¡ è¯·å°†æƒé‡æ–‡ä»¶é‡å‘½åä¸º: {config['weight_file']}")
            continue
        
        # åŠ è½½æ¨¡å‹
        print(f"  â³ åŠ è½½æƒé‡: {config['weight_file']}")
        model = load_model(weight_path, config["learnable_embedding"])
        
        # é¢„æµ‹ç²¾åº¦åˆ†æ
        mae = analyze_prediction_accuracy(model, plan_name, config["color"])
        
        # GOEè°±åˆ†æ
        goe_result = analyze_goe_spectrum(model, plan_name, config["color"])
        
        results[plan_name] = {
            "mae": mae,
            "goe": goe_result
        }
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    print("\n" + "="*60)
    print("ğŸ“Š å®éªŒæ±‡æ€»")
    print("="*60)
    for plan_name, result in results.items():
        print(f"\nã€{plan_name}ã€‘")
        print(f"  é¢„æµ‹ç²¾åº¦: MAE = {result['mae']:.4f}")
        if result['goe']:
            print(f"  è°±åˆ†æ: {result['goe']['verdict']}")
            print(f"    - è·ç¦»GOE: {result['goe']['d_goe']:.4f}")
            print(f"    - è·ç¦»Poisson: {result['goe']['d_poisson']:.4f}")
    
    print("\n" + "="*60)
    print(f"âœ… æ‰€æœ‰å›¾ç‰‡å·²ä¿å­˜è‡³: {OUTPUT_DIR}")
    print("="*60)

if __name__ == "__main__":
    main()
